#!/usr/bin/env python

"""Kafka Topic wrangler.

Usage:
  kafka-topic (create | delete | update | describe) [options] <name>
  kafka-topic (create-all | describe-all) [options]
  kafka-topic list [options]
  kafka-topic diff [options]

Options:
  -z host:port    Zookeeper host:port (Default: localhost:2181)
  -c config       topic.yml file (Default: $APP_HOME/config/topics.yml)
  -h, --help      Show this screen.
  --version       Show version.
  -d              Show debug info.
"""

from docopt import docopt
import subprocess
import os
from os import environ as env
import yaml
import collections
from texttable import Texttable

def get_app_home():
   try:
      return env['APP_HOME']
   except:
      return None

def get_kafka_home():
  return get_app_home()+"/deploy/confluent"


def read_cfg(args):
   config_file = "%s/bin/topics.yml" % (get_app_home(),)
   if args['-c'] is not None:
      config_file = args['-c']

   print "Reading config from %s \n" % (config_file, )
   
   return yaml.load(open(config_file, 'r'))

   
def load_cfg(args):
   config = read_cfg(args)
   topics = {}
   for topic in config.iteritems():
      name = topic[0]
      desc = topic[1]['description']

      for instance in topic[1]['instances']:
         i_name = instance
         i_desc = desc
         
         if isinstance(instance, collections.MutableMapping):
            i_name =  instance.keys()[0]
            if instance[i_name].has_key('description'):
               i_desc = "%s \n(%s)" % (desc, instance[i_name]['description'])
            else:
               i_desc = desc

         n = name + "." + i_name
         topics[n] = {i[0]:i[1] for i in topic[1].iteritems() if not i[0] == "instances"}
         if isinstance(instance, collections.MutableMapping):
            topics[n].update(instance[i_name])
         topics[n]['description'] = i_desc

   return topics

def get_zk(args):
   zk = 'localhost:2181'
   if args['-z'] is not None:
      zk = args['-z']
   return zk

def run_command(cmd):  
  print subprocess.call(cmd, shell=True)


def create(args):
  print "in create"
  name = args['<name>']
  config = read_cfg(args)
  name = args['<name>']
  print "in create"
  if not config.has_key(name):
      print config
      print "Topic %s is not available in the config file." %name
  else:
     create_topic(name, config[name]['partitions'], config[name]['replicas'], get_zk(args))
  #create_topic(name, 8, 1, get_zk(args))
    

def create_topic(topic, partitions, replicas, zk):
  print "in create_topic"
  cmd = "%s/bin/kafka-topics --zookeeper %s --topic %s --create --partitions %s --replication-factor %s" \
      % (get_kafka_home(),zk, topic, partitions, replicas)
  print "Running : " , cmd

  run_command(cmd)
   
def create_all(args):
   for topic in load_cfg(args).iteritems():
      create_topic(topic[0], topic[1]['partitions'], topic[1]['replicas'], get_zk(args))

def list(args):
   config = load_cfg(args)

   t = [["Topic", "Description","Properties"]]
   for x in sorted(config):
      props = " , ".join([ i[0] + "=" + str(i[1]) for i in config[x].iteritems() if not i[0] == "description" ])
      t.append([x, config[x]['description'], props ])
   table = Texttable(max_width=200)
   table.add_rows(t)
   print(table.draw())
   print ""      


def delete(args):
  zk=args['-z']
  topic1 = args['<name>']
  cmd = "%s/bin/kafka-topics --zookeeper %s --topic %s --delete" \
    % (get_kafka_home(), zk, topic1)
  print "Running : " , cmd
  run_command(cmd)



def describe(args):
  zk=args['-z']
  topic = args['<name>']
  cmd = "%s/bin/kafka-topics --zookeeper %s --topic %s --describe" \
    % (get_kafka_home(), zk, topic)
  print "Running : " , cmd
  run_command(cmd)

def describe_all(args):
   for topic in load_cfg(args).iteritems():
      describe(topic[0], get_zk(args))


def update(args):
  #get the current properties
  flag=0
  zk=args['-z']
  topic = args['<name>']
  print "in update fn"
  cmd = "%s/bin/kafka-topics --zookeeper %s --topic %s --describe" \
    % (get_kafka_home(),zk, topic)
  print "Running : " , cmd
  run_command(cmd)
  proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
  output = proc.stdout.read()
  output=str(output)
  print output
  splitProperties1=output.split("\n")
  splitProperties=splitProperties1[0].split("\t")
  currentTopic=splitProperties[0].split(":")
  currentPartitionCount=splitProperties[1].split(":")
  currentReplicationFactor=splitProperties[2].split(":")

  print currentTopic[1]
  print currentPartitionCount[1]
  print currentReplicationFactor[1]

  
  #get properties from yaml and update
  for topics in load_cfg(args).iteritems():
    if topics[0]==topic:
      flag=1
      requiredPartition=topics[1]['partitions']
      requiredReplicationFactor=topics[1]['replicas']
  
  if flag==0:
    print "Topic does not exsist"


  
   #compare properties
  if int(requiredPartition)!= int(currentPartitionCount[1]):
    cmd1 = "%s/bin/kafka-topics --zookeeper %s --alter --topic %s --partitions %s" \
      % (get_kafka_home(), zk, topic, requiredPartition)
    if run_command(cmd1)==0:
      print "Updated topic"
  elif int(requiredReplicationFactor)!= int(currentReplicationFactor[1]):
    print "Replication-factor not same as required Replication Factor" 
  elif int(requiredPartition) == int(currentPartitionCount[1]) and int(requiredReplicationFactor) == int(currentReplicationFactor[1]):
    print "Properties do not require update"






if __name__ == '__main__':
   args = docopt(__doc__, version='0.0.1')
   print ""
   
   if args['-d']:
      print args

   #if get_kafka_home() is None:
   #   print "KAFKA_HOME is not defined."
   elif get_app_home() is None and not args['-c']:
      print "APP_HOME is not defined. You need to define APP_HOME or provide a config file."
   elif args['create-all']:
      create_all(args)
   elif args['create']:
      create(args)
   elif args['list']:
      list(args)
   elif args['delete']:
      delete(args)
   elif args['describe']:
      describe(args)
   elif args['describe-all']:
      describe_all()
   elif args['update']:
      update(args)

